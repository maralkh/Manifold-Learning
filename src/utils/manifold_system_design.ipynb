{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fca3c5b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'redis'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlogging\u001b[39;00m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mconcurrent\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfutures\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ThreadPoolExecutor, ProcessPoolExecutor\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mredis\u001b[39;00m\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01muuid\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'redis'"
     ]
    }
   ],
   "source": [
    "# System Design for Large-Scale Geometric ML Computations\n",
    "# From Mathematical Theory to Production Systems\n",
    "\n",
    "\"\"\"\n",
    "🎯 SYSTEM DESIGN GOALS:\n",
    "1. 🏗️ Scalable Architecture - Handle millions of documents/embeddings\n",
    "2. ⚡ Performance Optimization - Fast geometric computations  \n",
    "3. 🔧 Modular Design - Easy to extend and maintain\n",
    "4. 🌐 Distributed Computing - Scale across multiple machines\n",
    "5. 📊 Monitoring & Observability - Track performance and errors\n",
    "\n",
    "🔧 TECHNICAL CHALLENGES:\n",
    "- Geometric computations are O(n³) for n-dimensional manifolds\n",
    "- Christoffel symbols require expensive symbolic/numerical derivatives  \n",
    "- Geodesic computation involves solving differential equations\n",
    "- Memory usage scales quadratically with embedding dimensions\n",
    "- Real-time inference requirements vs computational complexity\n",
    "\n",
    "🚀 SOLUTIONS WE'LL IMPLEMENT:\n",
    "- Caching and memoization strategies\n",
    "- Approximate algorithms for large-scale\n",
    "- Distributed computation patterns\n",
    "- GPU acceleration for matrix operations\n",
    "- Microservices architecture for scalability\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import Dict, List, Tuple, Optional, Any, Protocol\n",
    "from abc import ABC, abstractmethod\n",
    "from dataclasses import dataclass, field\n",
    "from functools import lru_cache\n",
    "import asyncio\n",
    "import time\n",
    "import logging\n",
    "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\n",
    "import redis\n",
    "import json\n",
    "import uuid\n",
    "from contextlib import contextmanager\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"🏗️ SYSTEM DESIGN FOR GEOMETRIC ML COMPUTATIONS\")\n",
    "print(\"⚡ From Mathematical Theory to Production Scale\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ============================================================================\n",
    "# PART 1: ABSTRACT INTERFACES & DESIGN PATTERNS\n",
    "# ============================================================================\n",
    "\n",
    "class ManifoldInterface(Protocol):\n",
    "    \"\"\"\n",
    "    Abstract interface for all manifold implementations\n",
    "    This enables polymorphism and easy testing\n",
    "    \"\"\"\n",
    "    \n",
    "    def metric_tensor(self, point: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Compute Riemannian metric at given point\"\"\"\n",
    "        ...\n",
    "    \n",
    "    def christoffel_symbols(self, point: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Compute connection coefficients\"\"\"\n",
    "        ...\n",
    "    \n",
    "    def geodesic_distance(self, point1: np.ndarray, point2: np.ndarray) -> float:\n",
    "        \"\"\"Compute shortest distance between points\"\"\"\n",
    "        ...\n",
    "    \n",
    "    def parallel_transport(self, vector: np.ndarray, \n",
    "                          start: np.ndarray, end: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Transport vector along geodesic\"\"\"\n",
    "        ...\n",
    "\n",
    "@dataclass\n",
    "class GeometricComputationResult:\n",
    "    \"\"\"Standardized result container\"\"\"\n",
    "    result: Any\n",
    "    computation_time: float\n",
    "    memory_usage: float\n",
    "    cache_hit: bool = False\n",
    "    approximation_error: Optional[float] = None\n",
    "    metadata: Dict[str, Any] = field(default_factory=dict)\n",
    "\n",
    "class GeometricCache:\n",
    "    \"\"\"\n",
    "    Intelligent caching system for expensive geometric computations\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, max_memory_mb: int = 1000, redis_url: Optional[str] = None):\n",
    "        self.max_memory_mb = max_memory_mb\n",
    "        self.local_cache = {}\n",
    "        self.cache_stats = {'hits': 0, 'misses': 0, 'evictions': 0}\n",
    "        \n",
    "        # Optional Redis for distributed caching\n",
    "        self.redis_client = redis.Redis.from_url(redis_url) if redis_url else None\n",
    "        \n",
    "        print(f\"📦 Initialized GeometricCache with {max_memory_mb}MB local memory\")\n",
    "        if self.redis_client:\n",
    "            print(f\"🌐 Connected to Redis for distributed caching\")\n",
    "    \n",
    "    def _generate_key(self, computation_type: str, *args, **kwargs) -> str:\n",
    "        \"\"\"Generate unique cache key\"\"\"\n",
    "        key_data = {\n",
    "            'type': computation_type,\n",
    "            'args': [arg.tolist() if isinstance(arg, np.ndarray) else arg for arg in args],\n",
    "            'kwargs': kwargs\n",
    "        }\n",
    "        key_str = json.dumps(key_data, sort_keys=True)\n",
    "        return f\"geom:{hash(key_str) % (2**32)}\"\n",
    "    \n",
    "    @contextmanager\n",
    "    def cache_computation(self, computation_type: str, *args, **kwargs):\n",
    "        \"\"\"Context manager for automatic caching\"\"\"\n",
    "        cache_key = self._generate_key(computation_type, *args, **kwargs)\n",
    "        \n",
    "        # Try to get from cache\n",
    "        cached_result = self._get_cached(cache_key)\n",
    "        if cached_result is not None:\n",
    "            self.cache_stats['hits'] += 1\n",
    "            yield cached_result, True  # (result, cache_hit)\n",
    "            return\n",
    "        \n",
    "        # Cache miss - need to compute\n",
    "        self.cache_stats['misses'] += 1\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Placeholder for result - will be set by caller\n",
    "        result_container = {'result': None}\n",
    "        yield result_container, False\n",
    "        \n",
    "        # Store result in cache\n",
    "        if result_container['result'] is not None:\n",
    "            computation_time = time.time() - start_time\n",
    "            self._store_cached(cache_key, result_container['result'], computation_time)\n",
    "    \n",
    "    def _get_cached(self, key: str) -> Optional[Any]:\n",
    "        \"\"\"Get from local cache first, then Redis\"\"\"\n",
    "        # Local cache\n",
    "        if key in self.local_cache:\n",
    "            return self.local_cache[key]\n",
    "        \n",
    "        # Redis cache\n",
    "        if self.redis_client:\n",
    "            try:\n",
    "                cached_data = self.redis_client.get(key)\n",
    "                if cached_data:\n",
    "                    result = json.loads(cached_data)\n",
    "                    # Store in local cache for faster access\n",
    "                    self.local_cache[key] = result\n",
    "                    return result\n",
    "            except Exception as e:\n",
    "                logging.warning(f\"Redis cache error: {e}\")\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def _store_cached(self, key: str, result: Any, computation_time: float):\n",
    "        \"\"\"Store in both local and Redis cache\"\"\"\n",
    "        # Local cache\n",
    "        self.local_cache[key] = result\n",
    "        \n",
    "        # Redis cache with expiration\n",
    "        if self.redis_client:\n",
    "            try:\n",
    "                self.redis_client.setex(\n",
    "                    key, \n",
    "                    3600,  # 1 hour expiration\n",
    "                    json.dumps(result)\n",
    "                )\n",
    "            except Exception as e:\n",
    "                logging.warning(f\"Redis store error: {e}\")\n",
    "    \n",
    "    def get_stats(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get cache performance statistics\"\"\"\n",
    "        total_requests = self.cache_stats['hits'] + self.cache_stats['misses']\n",
    "        hit_rate = self.cache_stats['hits'] / max(1, total_requests)\n",
    "        \n",
    "        return {\n",
    "            'hit_rate': hit_rate,\n",
    "            'total_requests': total_requests,\n",
    "            'local_cache_size': len(self.local_cache),\n",
    "            **self.cache_stats\n",
    "        }\n",
    "\n",
    "# ============================================================================\n",
    "# PART 2: SCALABLE MANIFOLD COMPUTATIONS\n",
    "# ============================================================================\n",
    "\n",
    "class ScalableManifoldProcessor:\n",
    "    \"\"\"\n",
    "    Production-ready manifold computation engine\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 cache_size_mb: int = 1000,\n",
    "                 max_workers: int = 4,\n",
    "                 gpu_acceleration: bool = True,\n",
    "                 redis_url: Optional[str] = None):\n",
    "        \n",
    "        self.cache = GeometricCache(cache_size_mb, redis_url)\n",
    "        self.max_workers = max_workers\n",
    "        self.gpu_available = gpu_acceleration and torch.cuda.is_available()\n",
    "        \n",
    "        # Thread pool for CPU-intensive computations\n",
    "        self.thread_executor = ThreadPoolExecutor(max_workers=max_workers)\n",
    "        self.process_executor = ProcessPoolExecutor(max_workers=max_workers)\n",
    "        \n",
    "        print(f\"🚀 Initialized ScalableManifoldProcessor\")\n",
    "        print(f\"   Workers: {max_workers}\")\n",
    "        print(f\"   GPU: {'✅ Available' if self.gpu_available else '❌ Not available'}\")\n",
    "        print(f\"   Cache: {cache_size_mb}MB\")\n",
    "    \n",
    "    async def compute_geodesic_distances_batch(self, \n",
    "                                             manifold: ManifoldInterface,\n",
    "                                             points1: np.ndarray,\n",
    "                                             points2: np.ndarray,\n",
    "                                             use_approximation: bool = False) -> List[GeometricComputationResult]:\n",
    "        \"\"\"\n",
    "        Compute geodesic distances for large batches efficiently\n",
    "        \n",
    "        Args:\n",
    "            manifold: Manifold implementation\n",
    "            points1: Array of shape (n, manifold_dim) \n",
    "            points2: Array of shape (n, manifold_dim)\n",
    "            use_approximation: Use faster approximate methods\n",
    "        \"\"\"\n",
    "        print(f\"📊 Computing {len(points1)} geodesic distances...\")\n",
    "        \n",
    "        if use_approximation and len(points1) > 1000:\n",
    "            return await self._compute_distances_approximate(manifold, points1, points2)\n",
    "        else:\n",
    "            return await self._compute_distances_exact(manifold, points1, points2)\n",
    "    \n",
    "    async def _compute_distances_exact(self, manifold, points1, points2):\n",
    "        \"\"\"Exact geodesic distance computation with parallelization\"\"\"\n",
    "        \n",
    "        async def compute_single_distance(i):\n",
    "            with self.cache.cache_computation('geodesic_distance', points1[i], points2[i]) as (cached, is_hit):\n",
    "                if is_hit:\n",
    "                    return GeometricComputationResult(\n",
    "                        result=cached,\n",
    "                        computation_time=0.0,\n",
    "                        memory_usage=0.0,\n",
    "                        cache_hit=True\n",
    "                    )\n",
    "                \n",
    "                start_time = time.time()\n",
    "                distance = manifold.geodesic_distance(points1[i], points2[i])\n",
    "                computation_time = time.time() - start_time\n",
    "                \n",
    "                cached['result'] = distance\n",
    "                \n",
    "                return GeometricComputationResult(\n",
    "                    result=distance,\n",
    "                    computation_time=computation_time,\n",
    "                    memory_usage=0.0,  # TODO: Track actual memory\n",
    "                    cache_hit=False\n",
    "                )\n",
    "        \n",
    "        # Parallel computation\n",
    "        tasks = [compute_single_distance(i) for i in range(len(points1))]\n",
    "        results = await asyncio.gather(*tasks)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    async def _compute_distances_approximate(self, manifold, points1, points2):\n",
    "        \"\"\"Fast approximate geodesic distances for large-scale\"\"\"\n",
    "        print(\"⚡ Using approximate geodesic computation for large batch\")\n",
    "        \n",
    "        # Strategy: Use GPU-accelerated Euclidean distances as approximation\n",
    "        # with learned correction factors\n",
    "        \n",
    "        if self.gpu_available:\n",
    "            points1_tensor = torch.from_numpy(points1).cuda()\n",
    "            points2_tensor = torch.from_numpy(points2).cuda()\n",
    "            \n",
    "            # Euclidean distances\n",
    "            euclidean_dists = torch.norm(points1_tensor - points2_tensor, dim=1)\n",
    "            \n",
    "            # Learned correction factor (would be trained in practice)\n",
    "            correction_factor = 1.2  # Approximation: geodesic ≈ 1.2 × euclidean\n",
    "            approximate_geodesics = euclidean_dists * correction_factor\n",
    "            \n",
    "            results = []\n",
    "            for i, dist in enumerate(approximate_geodesics.cpu().numpy()):\n",
    "                results.append(GeometricComputationResult(\n",
    "                    result=float(dist),\n",
    "                    computation_time=0.001,  # Very fast\n",
    "                    memory_usage=0.0,\n",
    "                    approximation_error=0.1,  # Estimated 10% error\n",
    "                    metadata={'method': 'gpu_approximate'}\n",
    "                ))\n",
    "            \n",
    "            return results\n",
    "        else:\n",
    "            # CPU fallback\n",
    "            results = []\n",
    "            for i in range(len(points1)):\n",
    "                euclidean_dist = np.linalg.norm(points1[i] - points2[i])\n",
    "                approximate_geodesic = euclidean_dist * 1.2\n",
    "                \n",
    "                results.append(GeometricComputationResult(\n",
    "                    result=approximate_geodesic,\n",
    "                    computation_time=0.001,\n",
    "                    memory_usage=0.0,\n",
    "                    approximation_error=0.15,  # Higher error on CPU\n",
    "                    metadata={'method': 'cpu_approximate'}\n",
    "                ))\n",
    "            \n",
    "            return results\n",
    "    \n",
    "    def compute_christoffel_symbols_efficient(self, \n",
    "                                            manifold: ManifoldInterface,\n",
    "                                            points: np.ndarray,\n",
    "                                            use_numerical: bool = True) -> List[GeometricComputationResult]:\n",
    "        \"\"\"\n",
    "        Efficient computation of Christoffel symbols with caching\n",
    "        \"\"\"\n",
    "        print(f\"🧮 Computing Christoffel symbols for {len(points)} points...\")\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        for i, point in enumerate(points):\n",
    "            with self.cache.cache_computation('christoffel', point, use_numerical) as (cached, is_hit):\n",
    "                if is_hit:\n",
    "                    results.append(GeometricComputationResult(\n",
    "                        result=cached,\n",
    "                        computation_time=0.0,\n",
    "                        memory_usage=0.0,\n",
    "                        cache_hit=True\n",
    "                    ))\n",
    "                    continue\n",
    "                \n",
    "                start_time = time.time()\n",
    "                \n",
    "                if use_numerical:\n",
    "                    # Numerical computation (faster but less accurate)\n",
    "                    symbols = self._compute_christoffel_numerical(manifold, point)\n",
    "                else:\n",
    "                    # Analytical computation (slower but exact)\n",
    "                    symbols = manifold.christoffel_symbols(point)\n",
    "                \n",
    "                computation_time = time.time() - start_time\n",
    "                cached['result'] = symbols.tolist()  # JSON serializable\n",
    "                \n",
    "                results.append(GeometricComputationResult(\n",
    "                    result=symbols,\n",
    "                    computation_time=computation_time,\n",
    "                    memory_usage=symbols.nbytes / 1024 / 1024,  # MB\n",
    "                    cache_hit=False,\n",
    "                    metadata={'method': 'numerical' if use_numerical else 'analytical'}\n",
    "                ))\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _compute_christoffel_numerical(self, manifold, point, epsilon=1e-6):\n",
    "        \"\"\"\n",
    "        Numerical approximation of Christoffel symbols using finite differences\n",
    "        Much faster than symbolic computation\n",
    "        \"\"\"\n",
    "        dim = len(point)\n",
    "        christoffel = np.zeros((dim, dim, dim))\n",
    "        \n",
    "        # Finite difference approximation of derivatives\n",
    "        for i in range(dim):\n",
    "            for j in range(dim):\n",
    "                for k in range(dim):\n",
    "                    # Approximate ∂g_ij/∂x_k using finite differences\n",
    "                    point_plus = point.copy()\n",
    "                    point_minus = point.copy()\n",
    "                    \n",
    "                    point_plus[k] += epsilon\n",
    "                    point_minus[k] -= epsilon\n",
    "                    \n",
    "                    try:\n",
    "                        g_plus = manifold.metric_tensor(point_plus)\n",
    "                        g_minus = manifold.metric_tensor(point_minus)\n",
    "                        \n",
    "                        # Central difference\n",
    "                        dg_ij_dx_k = (g_plus[i, j] - g_minus[i, j]) / (2 * epsilon)\n",
    "                        \n",
    "                        # This is simplified - full implementation needs inverse metric\n",
    "                        christoffel[k, i, j] += dg_ij_dx_k  # Approximation\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        logging.warning(f\"Numerical Christoffel computation error: {e}\")\n",
    "        \n",
    "        return christoffel\n",
    "\n",
    "# ============================================================================\n",
    "# PART 3: MICROSERVICES ARCHITECTURE\n",
    "# ============================================================================\n",
    "\n",
    "class GeometricComputationService:\n",
    "    \"\"\"\n",
    "    Microservice for geometric computations\n",
    "    RESTful API with async processing\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, processor: ScalableManifoldProcessor):\n",
    "        self.processor = processor\n",
    "        self.active_computations = {}  # Track ongoing computations\n",
    "        \n",
    "    async def create_computation_job(self, \n",
    "                                   job_type: str,\n",
    "                                   data: Dict[str, Any],\n",
    "                                   priority: int = 1) -> str:\n",
    "        \"\"\"\n",
    "        Create an asynchronous computation job\n",
    "        Returns job_id for tracking\n",
    "        \"\"\"\n",
    "        job_id = str(uuid.uuid4())\n",
    "        \n",
    "        job_info = {\n",
    "            'job_id': job_id,\n",
    "            'job_type': job_type,\n",
    "            'data': data,\n",
    "            'priority': priority,\n",
    "            'status': 'queued',\n",
    "            'created_at': time.time(),\n",
    "            'result': None,\n",
    "            'error': None\n",
    "        }\n",
    "        \n",
    "        self.active_computations[job_id] = job_info\n",
    "        \n",
    "        # Start computation asynchronously\n",
    "        asyncio.create_task(self._process_job(job_id))\n",
    "        \n",
    "        print(f\"📋 Created computation job {job_id} (type: {job_type})\")\n",
    "        return job_id\n",
    "    \n",
    "    async def _process_job(self, job_id: str):\n",
    "        \"\"\"Process a computation job\"\"\"\n",
    "        job = self.active_computations[job_id]\n",
    "        \n",
    "        try:\n",
    "            job['status'] = 'processing'\n",
    "            job['started_at'] = time.time()\n",
    "            \n",
    "            # Route to appropriate computation\n",
    "            if job['job_type'] == 'geodesic_distances':\n",
    "                result = await self._compute_geodesic_distances_job(job['data'])\n",
    "            elif job['job_type'] == 'christoffel_symbols':\n",
    "                result = await self._compute_christoffel_symbols_job(job['data'])\n",
    "            elif job['job_type'] == 'manifold_embedding':\n",
    "                result = await self._compute_manifold_embedding_job(job['data'])\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown job type: {job['job_type']}\")\n",
    "            \n",
    "            job['status'] = 'completed'\n",
    "            job['result'] = result\n",
    "            job['completed_at'] = time.time()\n",
    "            \n",
    "        except Exception as e:\n",
    "            job['status'] = 'failed'\n",
    "            job['error'] = str(e)\n",
    "            job['failed_at'] = time.time()\n",
    "            logging.error(f\"Job {job_id} failed: {e}\")\n",
    "    \n",
    "    async def get_job_status(self, job_id: str) -> Dict[str, Any]:\n",
    "        \"\"\"Get status and results of a computation job\"\"\"\n",
    "        if job_id not in self.active_computations:\n",
    "            return {'error': 'Job not found'}\n",
    "        \n",
    "        job = self.active_computations[job_id]\n",
    "        \n",
    "        # Calculate metrics\n",
    "        if 'started_at' in job:\n",
    "            if job['status'] == 'completed':\n",
    "                duration = job['completed_at'] - job['started_at']\n",
    "            elif job['status'] == 'processing':\n",
    "                duration = time.time() - job['started_at']\n",
    "            else:\n",
    "                duration = 0\n",
    "        else:\n",
    "            duration = 0\n",
    "        \n",
    "        return {\n",
    "            'job_id': job_id,\n",
    "            'status': job['status'],\n",
    "            'duration': duration,\n",
    "            'result': job.get('result'),\n",
    "            'error': job.get('error'),\n",
    "            'metadata': {\n",
    "                'job_type': job['job_type'],\n",
    "                'priority': job['priority'],\n",
    "                'created_at': job['created_at']\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    async def _compute_geodesic_distances_job(self, data: Dict[str, Any]):\n",
    "        \"\"\"Process geodesic distance computation job\"\"\"\n",
    "        points1 = np.array(data['points1'])\n",
    "        points2 = np.array(data['points2'])\n",
    "        manifold_type = data.get('manifold_type', 'sphere')\n",
    "        \n",
    "        # Create manifold instance (simplified)\n",
    "        if manifold_type == 'sphere':\n",
    "            from your_manifold_module import SphereManifold  # Import your implementation\n",
    "            manifold = SphereManifold(radius=data.get('radius', 1.0))\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported manifold type: {manifold_type}\")\n",
    "        \n",
    "        # Compute distances\n",
    "        results = await self.processor.compute_geodesic_distances_batch(\n",
    "            manifold, points1, points2, \n",
    "            use_approximation=data.get('use_approximation', False)\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'distances': [r.result for r in results],\n",
    "            'computation_times': [r.computation_time for r in results],\n",
    "            'cache_hits': sum(1 for r in results if r.cache_hit),\n",
    "            'total_points': len(points1)\n",
    "        }\n",
    "\n",
    "# ============================================================================\n",
    "# PART 4: MONITORING AND OBSERVABILITY\n",
    "# ============================================================================\n",
    "\n",
    "class GeometricComputationMonitor:\n",
    "    \"\"\"\n",
    "    Monitoring and observability for geometric computations\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.metrics = {\n",
    "            'total_computations': 0,\n",
    "            'total_computation_time': 0.0,\n",
    "            'cache_hit_rate': 0.0,\n",
    "            'error_rate': 0.0,\n",
    "            'memory_usage_mb': 0.0,\n",
    "            'gpu_utilization': 0.0\n",
    "        }\n",
    "        \n",
    "        self.computation_history = []\n",
    "        \n",
    "    def record_computation(self, result: GeometricComputationResult, \n",
    "                         computation_type: str):\n",
    "        \"\"\"Record metrics for a computation\"\"\"\n",
    "        self.metrics['total_computations'] += 1\n",
    "        self.metrics['total_computation_time'] += result.computation_time\n",
    "        \n",
    "        # Store detailed history\n",
    "        self.computation_history.append({\n",
    "            'timestamp': time.time(),\n",
    "            'type': computation_type,\n",
    "            'computation_time': result.computation_time,\n",
    "            'memory_usage': result.memory_usage,\n",
    "            'cache_hit': result.cache_hit,\n",
    "            'approximation_error': result.approximation_error\n",
    "        })\n",
    "        \n",
    "        # Keep only last 1000 entries\n",
    "        if len(self.computation_history) > 1000:\n",
    "            self.computation_history = self.computation_history[-1000:]\n",
    "    \n",
    "    def get_performance_summary(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get comprehensive performance summary\"\"\"\n",
    "        if not self.computation_history:\n",
    "            return {'message': 'No computations recorded yet'}\n",
    "        \n",
    "        recent_computations = self.computation_history[-100:]  # Last 100\n",
    "        \n",
    "        avg_computation_time = np.mean([c['computation_time'] for c in recent_computations])\n",
    "        cache_hit_rate = np.mean([c['cache_hit'] for c in recent_computations])\n",
    "        avg_memory_usage = np.mean([c['memory_usage'] for c in recent_computations if c['memory_usage'] > 0])\n",
    "        \n",
    "        return {\n",
    "            'total_computations': self.metrics['total_computations'],\n",
    "            'average_computation_time': avg_computation_time,\n",
    "            'cache_hit_rate': cache_hit_rate,\n",
    "            'average_memory_usage_mb': avg_memory_usage,\n",
    "            'computations_per_second': len(recent_computations) / max(1, recent_computations[-1]['timestamp'] - recent_computations[0]['timestamp']),\n",
    "            'error_rate': 0.0,  # TODO: Track errors\n",
    "            'recommendations': self._generate_recommendations(recent_computations)\n",
    "        }\n",
    "    \n",
    "    def _generate_recommendations(self, recent_computations: List[Dict]) -> List[str]:\n",
    "        \"\"\"Generate performance optimization recommendations\"\"\"\n",
    "        recommendations = []\n",
    "        \n",
    "        cache_hit_rate = np.mean([c['cache_hit'] for c in recent_computations])\n",
    "        if cache_hit_rate < 0.5:\n",
    "            recommendations.append(\"🔥 Low cache hit rate - consider increasing cache size\")\n",
    "        \n",
    "        avg_time = np.mean([c['computation_time'] for c in recent_computations])\n",
    "        if avg_time > 1.0:\n",
    "            recommendations.append(\"⚡ High computation times - consider using approximation methods\")\n",
    "        \n",
    "        if len([c for c in recent_computations if c['approximation_error'] and c['approximation_error'] > 0.2]) > 0:\n",
    "            recommendations.append(\"🎯 High approximation errors - consider exact methods for critical computations\")\n",
    "        \n",
    "        return recommendations\n",
    "\n",
    "# ============================================================================\n",
    "# PART 5: INTEGRATION EXAMPLE\n",
    "# ============================================================================\n",
    "\n",
    "class ProductionGeometricSystem:\n",
    "    \"\"\"\n",
    "    Complete production system integrating all components\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.processor = ScalableManifoldProcessor(\n",
    "            cache_size_mb=2000,\n",
    "            max_workers=8,\n",
    "            gpu_acceleration=True\n",
    "        )\n",
    "        \n",
    "        self.service = GeometricComputationService(self.processor)\n",
    "        self.monitor = GeometricComputationMonitor()\n",
    "        \n",
    "        print(\"🏭 Production Geometric System initialized\")\n",
    "        print(\"   Ready for large-scale manifold computations!\")\n",
    "    \n",
    "    async def process_document_batch(self, documents: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Example: Process a batch of documents using geometric methods\n",
    "        This connects back to your document intelligence project!\n",
    "        \"\"\"\n",
    "        print(f\"📄 Processing {len(documents)} documents with geometric methods...\")\n",
    "        \n",
    "        # Extract embeddings (simplified)\n",
    "        embeddings = []\n",
    "        for doc in documents:\n",
    "            # In practice, this would use your embedding model\n",
    "            embedding = np.random.randn(64)  # Mock 64D embedding\n",
    "            embeddings.append(embedding)\n",
    "        \n",
    "        embeddings = np.array(embeddings)\n",
    "        \n",
    "        # Create computation job for manifold analysis\n",
    "        job_data = {\n",
    "            'points1': embeddings[:-1].tolist(),  # All but last\n",
    "            'points2': embeddings[1:].tolist(),   # All but first\n",
    "            'manifold_type': 'sphere',\n",
    "            'use_approximation': len(documents) > 100\n",
    "        }\n",
    "        \n",
    "        job_id = await self.service.create_computation_job(\n",
    "            'geodesic_distances', job_data, priority=1\n",
    "        )\n",
    "        \n",
    "        # Wait for completion (in practice, would be async)\n",
    "        while True:\n",
    "            status = await self.service.get_job_status(job_id)\n",
    "            if status['status'] in ['completed', 'failed']:\n",
    "                break\n",
    "            await asyncio.sleep(0.1)\n",
    "        \n",
    "        if status['status'] == 'completed':\n",
    "            distances = status['result']['distances']\n",
    "            \n",
    "            # Analyze document relationships using geometric distances\n",
    "            similarity_threshold = np.percentile(distances, 25)  # Bottom quartile\n",
    "            similar_pairs = [(i, i+1) for i, d in enumerate(distances) if d < similarity_threshold]\n",
    "            \n",
    "            return {\n",
    "                'total_documents': len(documents),\n",
    "                'geometric_distances': distances,\n",
    "                'similar_document_pairs': similar_pairs,\n",
    "                'processing_time': status['duration'],\n",
    "                'cache_performance': self.processor.cache.get_stats()\n",
    "            }\n",
    "        else:\n",
    "            return {'error': status['error']}\n",
    "\n",
    "# ============================================================================\n",
    "# DEMONSTRATION AND TESTING\n",
    "# ============================================================================\n",
    "\n",
    "async def demonstrate_system_design():\n",
    "    \"\"\"\n",
    "    Demonstrate the complete geometric system design\n",
    "    \"\"\"\n",
    "    print(\"\\n🚀 DEMONSTRATING PRODUCTION GEOMETRIC SYSTEM\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Initialize system\n",
    "    system = ProductionGeometricSystem()\n",
    "    \n",
    "    # Create mock documents\n",
    "    documents = [\n",
    "        {'id': i, 'content': f'Document {i}', 'category': f'cat_{i%3}'}\n",
    "        for i in range(50)\n",
    "    ]\n",
    "    \n",
    "    # Process documents\n",
    "    result = await system.process_document_batch(documents)\n",
    "    \n",
    "    print(\"\\n📊 PROCESSING RESULTS:\")\n",
    "    print(f\"   Documents processed: {result['total_documents']}\")\n",
    "    print(f\"   Average distance: {np.mean(result['geometric_distances']):.4f}\")\n",
    "    print(f\"   Similar pairs found: {len(result['similar_document_pairs'])}\")\n",
    "    print(f\"   Processing time: {result['processing_time']:.2f}s\")\n",
    "    \n",
    "    cache_stats = result['cache_performance']\n",
    "    print(f\"\\n📦 CACHE PERFORMANCE:\")\n",
    "    print(f\"   Hit rate: {cache_stats['hit_rate']:.1%}\")\n",
    "    print(f\"   Total requests: {cache_stats['total_requests']}\")\n",
    "    \n",
    "    # Monitor performance\n",
    "    performance = system.monitor.get_performance_summary()\n",
    "    print(f\"\\n📈 SYSTEM PERFORMANCE:\")\n",
    "    print(f\"   Total computations: {performance.get('total_computations', 0)}\")\n",
    "    if 'recommendations' in performance:\n",
    "        print(f\"   Recommendations:\")\n",
    "        for rec in performance['recommendations']:\n",
    "            print(f\"     {rec}\")\n",
    "    \n",
    "    return system\n",
    "\n",
    "# ============================================================================\n",
    "# YOUR LEARNING EXERCISES\n",
    "# ============================================================================\n",
    "\n",
    "def system_design_exercises():\n",
    "    \"\"\"\n",
    "    Advanced system design exercises\n",
    "    \"\"\"\n",
    "    print(\"\\n🎯 SYSTEM DESIGN LEARNING EXERCISES\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    exercises = {\n",
    "        \"1. 🏗️ Database Design\": {\n",
    "            \"task\": \"Design database schema for storing manifold computations\",\n",
    "            \"focus\": \"Efficient storage of geometric data, indexing strategies\",\n",
    "            \"difficulty\": \"⭐⭐⭐\"\n",
    "        },\n",
    "        \n",
    "        \"2. ⚡ Performance Optimization\": {\n",
    "            \"task\": \"Implement GPU-accelerated Christoffel symbol computation\",\n",
    "            \"focus\": \"CUDA/PyTorch optimization, memory management\",\n",
    "            \"difficulty\": \"⭐⭐⭐⭐\"\n",
    "        },\n",
    "        \n",
    "        \"3. 🌐 Distributed Computing\": {\n",
    "            \"task\": \"Design distributed geodesic computation across multiple machines\",\n",
    "            \"focus\": \"Load balancing, fault tolerance, data partitioning\",\n",
    "            \"difficulty\": \"⭐⭐⭐⭐\"\n",
    "        },\n",
    "        \n",
    "        \"4. 📊 Advanced Monitoring\": {\n",
    "            \"task\": \"Implement real-time performance dashboards\",\n",
    "            \"focus\": \"Metrics collection, alerting, visualization\",\n",
    "            \"difficulty\": \"⭐⭐⭐\"\n",
    "        },\n",
    "        \n",
    "        \"5. 🔧 Auto-Scaling\": {\n",
    "            \"task\": \"Design auto-scaling based on computation load\",\n",
    "            \"focus\": \"Load prediction, resource management, cost optimization\",\n",
    "            \"difficulty\": \"⭐⭐⭐⭐⭐\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    for name, details in exercises.items():\n",
    "        print(f\"\\n{name}\")\n",
    "        print(f\"   Task: {details['task']}\")\n",
    "        print(f\"   Focus: {details['focus']}\")\n",
    "        print(f\"   Difficulty: {details['difficulty']}\")\n",
    "    \n",
    "    print(f\"\\n💡 Pick one that interests you most!\")\n",
    "    return exercises\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN EXECUTION\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"🚀 Starting System Design Demonstration...\")\n",
    "    \n",
    "    # Run the demonstration\n",
    "    import asyncio\n",
    "    system = asyncio.run(demonstrate_system_design())\n",
    "    \n",
    "    # Show exercises\n",
    "    exercises = system_design_exercises()\n",
    "    \n",
    "    print(\"\\n🎓 SYSTEM DESIGN CONCEPTS COVERED:\")\n",
    "    print(\"   ✅ Scalable architecture patterns\")\n",
    "    print(\"   ✅ Caching and performance optimization\") \n",
    "    print(\"   ✅ Microservices design\")\n",
    "    print(\"   ✅ Async processing and job queues\")\n",
    "    print(\"   ✅ Monitoring and observability\")\n",
    "    print(\"   ✅ Production deployment considerations\")\n",
    "    \n",
    "    print(\"\\n🔗 CONNECTION TO YOUR PORTFOLIO:\")\n",
    "    print(\"   🧠 Shows system design expertise beyond just algorithms\")\n",
    "    print(\"   ⚡ Demonstrates production scalability thinking\")\n",
    "    print(\"   🏗️ Microservices and distributed systems knowledge\")\n",
    "    print(\"   📊 Monitoring and observability best practices\")\n",
    "    print(\"   💼 Business-aware performance optimization\")\n",
    "    \n",
    "    print(\"\\n🎯 NEXT INTEGRATION STEPS:\")\n",
    "    print(\"   1. 🔌 Connect to your document intelligence system\")\n",
    "    print(\"   2. 🌐 Deploy geometric RAG with this architecture\")\n",
    "    print(\"   3. 📈 Add performance monitoring to your demos\")\n",
    "    print(\"   4. 🚀 Scale your multi-agent system using these patterns\")\n",
    "    \n",
    "    print(\"\\n💡 Ready for the integration challenges? 🚀\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
